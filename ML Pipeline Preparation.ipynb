{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('DisasterResponse', engine)  \n",
    "X = df.message\n",
    "Y = df.drop(labels=[\"id\",\"message\",\"original\",\"genre\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    # remove punctuation and tokenize\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    token = tokenizer.tokenize(text.lower())\n",
    "\n",
    "    # remove stop words:\n",
    "    stopwords_english = stopwords.words(\"english\")\n",
    "    tokens = [word for word in token if word not in stopwords_english]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"clf\", MultiOutputClassifier(KNeighborsClassifier(n_jobs=-1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.11      0.20      1245\n",
      "          1       0.78      0.99      0.87      3998\n",
      "\n",
      "avg / total       0.77      0.78      0.71      5243\n",
      "\n",
      "\n",
      " request \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.04      0.08      4352\n",
      "          1       0.17      0.99      0.30       891\n",
      "\n",
      "avg / total       0.82      0.20      0.12      5243\n",
      "\n",
      "\n",
      " offer \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5219\n",
      "          1       0.00      1.00      0.01        24\n",
      "\n",
      "avg / total       1.00      0.04      0.07      5243\n",
      "\n",
      "\n",
      " aid_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.06      0.11      3079\n",
      "          1       0.43      0.99      0.60      2164\n",
      "\n",
      "avg / total       0.73      0.45      0.31      5243\n",
      "\n",
      "\n",
      " medical_help \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.08      4808\n",
      "          1       0.09      1.00      0.16       435\n",
      "\n",
      "avg / total       0.92      0.12      0.08      5243\n",
      "\n",
      "\n",
      " medical_products \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.07      4964\n",
      "          1       0.06      1.00      0.10       279\n",
      "\n",
      "avg / total       0.94      0.09      0.08      5243\n",
      "\n",
      "\n",
      " search_and_rescue \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5107\n",
      "          1       0.03      1.00      0.05       136\n",
      "\n",
      "avg / total       0.97      0.06      0.07      5243\n",
      "\n",
      "\n",
      " security \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5147\n",
      "          1       0.02      1.00      0.04        96\n",
      "\n",
      "avg / total       0.98      0.06      0.07      5243\n",
      "\n",
      "\n",
      " military \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5085\n",
      "          1       0.03      1.00      0.06       158\n",
      "\n",
      "avg / total       0.97      0.07      0.07      5243\n",
      "\n",
      "\n",
      " child_alone \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5243\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.04      0.07      5243\n",
      "\n",
      "\n",
      " water \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.08      4908\n",
      "          1       0.07      1.00      0.12       335\n",
      "\n",
      "avg / total       0.94      0.10      0.08      5243\n",
      "\n",
      "\n",
      " food \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.08      4659\n",
      "          1       0.12      1.00      0.21       584\n",
      "\n",
      "avg / total       0.90      0.15      0.09      5243\n",
      "\n",
      "\n",
      " shelter \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.08      4775\n",
      "          1       0.09      1.00      0.17       468\n",
      "\n",
      "avg / total       0.91      0.13      0.09      5243\n",
      "\n",
      "\n",
      " clothing \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5173\n",
      "          1       0.01      1.00      0.03        70\n",
      "\n",
      "avg / total       0.99      0.05      0.07      5243\n",
      "\n",
      "\n",
      " money \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5131\n",
      "          1       0.02      1.00      0.04       112\n",
      "\n",
      "avg / total       0.98      0.06      0.07      5243\n",
      "\n",
      "\n",
      " missing_people \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5180\n",
      "          1       0.01      1.00      0.02        63\n",
      "\n",
      "avg / total       0.99      0.05      0.07      5243\n",
      "\n",
      "\n",
      " refugees \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5073\n",
      "          1       0.03      1.00      0.07       170\n",
      "\n",
      "avg / total       0.97      0.07      0.07      5243\n",
      "\n",
      "\n",
      " death \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      4996\n",
      "          1       0.05      1.00      0.09       247\n",
      "\n",
      "avg / total       0.96      0.08      0.08      5243\n",
      "\n",
      "\n",
      " other_aid \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.04      0.08      4551\n",
      "          1       0.14      0.99      0.24       692\n",
      "\n",
      "avg / total       0.85      0.17      0.10      5243\n",
      "\n",
      "\n",
      " infrastructure_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.08      4907\n",
      "          1       0.07      1.00      0.12       336\n",
      "\n",
      "avg / total       0.94      0.10      0.08      5243\n",
      "\n",
      "\n",
      " transport \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.07      5008\n",
      "          1       0.05      1.00      0.09       235\n",
      "\n",
      "avg / total       0.95      0.08      0.07      5243\n",
      "\n",
      "\n",
      " buildings \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.07      4974\n",
      "          1       0.05      1.00      0.10       269\n",
      "\n",
      "avg / total       0.95      0.09      0.08      5243\n",
      "\n",
      "\n",
      " electricity \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5128\n",
      "          1       0.02      1.00      0.04       115\n",
      "\n",
      "avg / total       0.98      0.06      0.07      5243\n",
      "\n",
      "\n",
      " tools \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.07      5208\n",
      "          1       0.01      0.97      0.01        35\n",
      "\n",
      "avg / total       0.99      0.04      0.07      5243\n",
      "\n",
      "\n",
      " hospitals \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5191\n",
      "          1       0.01      1.00      0.02        52\n",
      "\n",
      "avg / total       0.99      0.05      0.07      5243\n",
      "\n",
      "\n",
      " shops \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5218\n",
      "          1       0.00      1.00      0.01        25\n",
      "\n",
      "avg / total       1.00      0.04      0.07      5243\n",
      "\n",
      "\n",
      " aid_centers \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5179\n",
      "          1       0.01      1.00      0.03        64\n",
      "\n",
      "avg / total       0.99      0.05      0.07      5243\n",
      "\n",
      "\n",
      " other_infrastructure \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      5018\n",
      "          1       0.04      1.00      0.09       225\n",
      "\n",
      "avg / total       0.96      0.08      0.07      5243\n",
      "\n",
      "\n",
      " weather_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.05      0.09      3771\n",
      "          1       0.29      1.00      0.45      1472\n",
      "\n",
      "avg / total       0.78      0.32      0.19      5243\n",
      "\n",
      "\n",
      " floods \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.08      4812\n",
      "          1       0.09      1.00      0.16       431\n",
      "\n",
      "avg / total       0.92      0.12      0.08      5243\n",
      "\n",
      "\n",
      " storm \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.08      4764\n",
      "          1       0.09      1.00      0.17       479\n",
      "\n",
      "avg / total       0.91      0.13      0.09      5243\n",
      "\n",
      "\n",
      " fire \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.07      5190\n",
      "          1       0.01      0.98      0.02        53\n",
      "\n",
      "avg / total       0.98      0.05      0.07      5243\n",
      "\n",
      "\n",
      " earthquake \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.08      4728\n",
      "          1       0.10      1.00      0.19       515\n",
      "\n",
      "avg / total       0.91      0.14      0.09      5243\n",
      "\n",
      "\n",
      " cold \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.04      0.07      5139\n",
      "          1       0.02      0.99      0.04       104\n",
      "\n",
      "avg / total       0.98      0.06      0.07      5243\n",
      "\n",
      "\n",
      " other_weather \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07      4976\n",
      "          1       0.05      1.00      0.10       267\n",
      "\n",
      "avg / total       0.95      0.09      0.08      5243\n",
      "\n",
      "\n",
      " direct_report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.04      0.08      4233\n",
      "          1       0.20      0.99      0.33      1010\n",
      "\n",
      "avg / total       0.81      0.23      0.13      5243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def display_results(y_true, y_pred):\n",
    "    for column in Y.columns:\n",
    "        print(\"\\n\", column, \"\\n\")\n",
    "        print(classification_report(y_true[column], y_pred[:,0]))\n",
    "        \n",
    "y_pred = model.predict(X_test)\n",
    "display_results(Y, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"clf__estimator__n_neighbors\":[5,50,100]}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] clf__estimator__n_neighbors=5 ...................................\n",
      "[CV] .................... clf__estimator__n_neighbors=5, total= 1.9min\n",
      "[CV] clf__estimator__n_neighbors=5 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... clf__estimator__n_neighbors=5, total= 2.0min\n",
      "[CV] clf__estimator__n_neighbors=5 ...................................\n",
      "[CV] .................... clf__estimator__n_neighbors=5, total= 1.9min\n",
      "[CV] clf__estimator__n_neighbors=50 ..................................\n",
      "[CV] ................... clf__estimator__n_neighbors=50, total= 2.0min\n",
      "[CV] clf__estimator__n_neighbors=50 ..................................\n",
      "[CV] ................... clf__estimator__n_neighbors=50, total= 2.0min\n",
      "[CV] clf__estimator__n_neighbors=50 ..................................\n",
      "[CV] ................... clf__estimator__n_neighbors=50, total= 1.9min\n",
      "[CV] clf__estimator__n_neighbors=100 .................................\n",
      "[CV] .................. clf__estimator__n_neighbors=100, total= 2.0min\n",
      "[CV] clf__estimator__n_neighbors=100 .................................\n",
      "[CV] .................. clf__estimator__n_neighbors=100, total= 2.0min\n",
      "[CV] clf__estimator__n_neighbors=100 .................................\n",
      "[CV] .................. clf__estimator__n_neighbors=100, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 52.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.27      0.39      1245\n",
      "          1       0.81      0.97      0.88      3998\n",
      "\n",
      "avg / total       0.79      0.80      0.77      5243\n",
      "\n",
      "\n",
      " request \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.10      0.19      4352\n",
      "          1       0.18      0.98      0.31       891\n",
      "\n",
      "avg / total       0.83      0.25      0.21      5243\n",
      "\n",
      "\n",
      " offer \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5219\n",
      "          1       0.01      1.00      0.01        24\n",
      "\n",
      "avg / total       1.00      0.09      0.16      5243\n",
      "\n",
      "\n",
      " aid_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.14      0.25      3079\n",
      "          1       0.45      0.99      0.62      2164\n",
      "\n",
      "avg / total       0.74      0.49      0.40      5243\n",
      "\n",
      "\n",
      " medical_help \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.10      0.17      4808\n",
      "          1       0.09      0.99      0.17       435\n",
      "\n",
      "avg / total       0.92      0.17      0.17      5243\n",
      "\n",
      "\n",
      " medical_products \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      4964\n",
      "          1       0.06      0.99      0.11       279\n",
      "\n",
      "avg / total       0.95      0.14      0.17      5243\n",
      "\n",
      "\n",
      " search_and_rescue \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      5107\n",
      "          1       0.03      0.99      0.05       136\n",
      "\n",
      "avg / total       0.97      0.11      0.16      5243\n",
      "\n",
      "\n",
      " security \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.09      0.16      5147\n",
      "          1       0.02      0.97      0.04        96\n",
      "\n",
      "avg / total       0.98      0.11      0.16      5243\n",
      "\n",
      "\n",
      " military \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      5085\n",
      "          1       0.03      0.99      0.06       158\n",
      "\n",
      "avg / total       0.97      0.12      0.16      5243\n",
      "\n",
      "\n",
      " child_alone \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5243\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.09      0.16      5243\n",
      "\n",
      "\n",
      " water \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.09      0.17      4908\n",
      "          1       0.07      0.99      0.13       335\n",
      "\n",
      "avg / total       0.93      0.15      0.17      5243\n",
      "\n",
      "\n",
      " food \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.10      0.18      4659\n",
      "          1       0.12      0.99      0.22       584\n",
      "\n",
      "avg / total       0.89      0.20      0.18      5243\n",
      "\n",
      "\n",
      " shelter \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.10      0.17      4775\n",
      "          1       0.10      0.99      0.18       468\n",
      "\n",
      "avg / total       0.91      0.18      0.18      5243\n",
      "\n",
      "\n",
      " clothing \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5173\n",
      "          1       0.01      0.97      0.03        70\n",
      "\n",
      "avg / total       0.98      0.10      0.16      5243\n",
      "\n",
      "\n",
      " money \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      5131\n",
      "          1       0.02      0.99      0.05       112\n",
      "\n",
      "avg / total       0.98      0.11      0.16      5243\n",
      "\n",
      "\n",
      " missing_people \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5180\n",
      "          1       0.01      0.98      0.03        63\n",
      "\n",
      "avg / total       0.99      0.10      0.16      5243\n",
      "\n",
      "\n",
      " refugees \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      5073\n",
      "          1       0.04      0.99      0.07       170\n",
      "\n",
      "avg / total       0.96      0.12      0.16      5243\n",
      "\n",
      "\n",
      " death \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.09      0.17      4996\n",
      "          1       0.05      0.99      0.10       247\n",
      "\n",
      "avg / total       0.95      0.13      0.17      5243\n",
      "\n",
      "\n",
      " other_aid \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.10      0.18      4551\n",
      "          1       0.14      0.98      0.25       692\n",
      "\n",
      "avg / total       0.86      0.21      0.19      5243\n",
      "\n",
      "\n",
      " infrastructure_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      4907\n",
      "          1       0.07      0.99      0.13       336\n",
      "\n",
      "avg / total       0.94      0.15      0.17      5243\n",
      "\n",
      "\n",
      " transport \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.09      0.17      5008\n",
      "          1       0.05      0.98      0.09       235\n",
      "\n",
      "avg / total       0.95      0.13      0.16      5243\n",
      "\n",
      "\n",
      " buildings \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      4974\n",
      "          1       0.06      0.99      0.11       269\n",
      "\n",
      "avg / total       0.95      0.14      0.17      5243\n",
      "\n",
      "\n",
      " electricity \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.09      0.16      5128\n",
      "          1       0.02      0.97      0.05       115\n",
      "\n",
      "avg / total       0.97      0.11      0.16      5243\n",
      "\n",
      "\n",
      " tools \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5208\n",
      "          1       0.01      0.97      0.01        35\n",
      "\n",
      "avg / total       0.99      0.09      0.16      5243\n",
      "\n",
      "\n",
      " hospitals \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5191\n",
      "          1       0.01      1.00      0.02        52\n",
      "\n",
      "avg / total       0.99      0.10      0.16      5243\n",
      "\n",
      "\n",
      " shops \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5218\n",
      "          1       0.01      0.96      0.01        25\n",
      "\n",
      "avg / total       0.99      0.09      0.16      5243\n",
      "\n",
      "\n",
      " aid_centers \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5179\n",
      "          1       0.01      1.00      0.03        64\n",
      "\n",
      "avg / total       0.99      0.10      0.16      5243\n",
      "\n",
      "\n",
      " other_infrastructure \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17      5018\n",
      "          1       0.05      1.00      0.09       225\n",
      "\n",
      "avg / total       0.96      0.13      0.17      5243\n",
      "\n",
      "\n",
      " weather_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.12      0.21      3771\n",
      "          1       0.31      0.99      0.47      1472\n",
      "\n",
      "avg / total       0.78      0.36      0.28      5243\n",
      "\n",
      "\n",
      " floods \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.10      0.17      4812\n",
      "          1       0.09      0.99      0.16       431\n",
      "\n",
      "avg / total       0.92      0.17      0.17      5243\n",
      "\n",
      "\n",
      " storm \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.10      0.18      4764\n",
      "          1       0.10      0.99      0.18       479\n",
      "\n",
      "avg / total       0.91      0.18      0.18      5243\n",
      "\n",
      "\n",
      " fire \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5190\n",
      "          1       0.01      0.96      0.02        53\n",
      "\n",
      "avg / total       0.99      0.10      0.16      5243\n",
      "\n",
      "\n",
      " earthquake \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.10      0.18      4728\n",
      "          1       0.11      0.99      0.19       515\n",
      "\n",
      "avg / total       0.90      0.19      0.18      5243\n",
      "\n",
      "\n",
      " cold \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16      5139\n",
      "          1       0.02      0.99      0.04       104\n",
      "\n",
      "avg / total       0.98      0.11      0.16      5243\n",
      "\n",
      "\n",
      " other_weather \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.09      0.17      4976\n",
      "          1       0.06      0.99      0.10       267\n",
      "\n",
      "avg / total       0.95      0.14      0.17      5243\n",
      "\n",
      "\n",
      " direct_report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.10      0.19      4233\n",
      "          1       0.21      0.98      0.34      1010\n",
      "\n",
      "avg / total       0.81      0.27      0.22      5243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.41      0.52      1245\n",
      "          1       0.84      0.94      0.89      3998\n",
      "\n",
      "avg / total       0.80      0.82      0.80      5243\n",
      "\n",
      "\n",
      " request \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.16      0.28      4352\n",
      "          1       0.19      0.97      0.32       891\n",
      "\n",
      "avg / total       0.84      0.30      0.29      5243\n",
      "\n",
      "\n",
      " offer \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5219\n",
      "          1       0.01      0.96      0.01        24\n",
      "\n",
      "avg / total       0.99      0.14      0.24      5243\n",
      "\n",
      "\n",
      " aid_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.23      0.37      3079\n",
      "          1       0.47      0.99      0.64      2164\n",
      "\n",
      "avg / total       0.76      0.54      0.48      5243\n",
      "\n",
      "\n",
      " medical_help \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.26      4808\n",
      "          1       0.10      0.99      0.17       435\n",
      "\n",
      "avg / total       0.92      0.22      0.25      5243\n",
      "\n",
      "\n",
      " medical_products \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.26      4964\n",
      "          1       0.06      0.99      0.11       279\n",
      "\n",
      "avg / total       0.94      0.19      0.25      5243\n",
      "\n",
      "\n",
      " search_and_rescue \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5107\n",
      "          1       0.03      0.99      0.06       136\n",
      "\n",
      "avg / total       0.97      0.16      0.25      5243\n",
      "\n",
      "\n",
      " security \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5147\n",
      "          1       0.02      0.97      0.04        96\n",
      "\n",
      "avg / total       0.98      0.16      0.24      5243\n",
      "\n",
      "\n",
      " military \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5085\n",
      "          1       0.03      0.99      0.07       158\n",
      "\n",
      "avg / total       0.97      0.17      0.25      5243\n",
      "\n",
      "\n",
      " child_alone \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5243\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.14      0.25      5243\n",
      "\n",
      "\n",
      " water \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.26      4908\n",
      "          1       0.07      1.00      0.14       335\n",
      "\n",
      "avg / total       0.94      0.20      0.25      5243\n",
      "\n",
      "\n",
      " food \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.16      0.27      4659\n",
      "          1       0.13      0.99      0.23       584\n",
      "\n",
      "avg / total       0.90      0.25      0.27      5243\n",
      "\n",
      "\n",
      " shelter \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27      4775\n",
      "          1       0.10      1.00      0.19       468\n",
      "\n",
      "avg / total       0.92      0.23      0.26      5243\n",
      "\n",
      "\n",
      " clothing \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5173\n",
      "          1       0.02      1.00      0.03        70\n",
      "\n",
      "avg / total       0.99      0.15      0.25      5243\n",
      "\n",
      "\n",
      " money \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5131\n",
      "          1       0.02      0.98      0.05       112\n",
      "\n",
      "avg / total       0.98      0.16      0.24      5243\n",
      "\n",
      "\n",
      " missing_people \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5180\n",
      "          1       0.01      1.00      0.03        63\n",
      "\n",
      "avg / total       0.99      0.15      0.24      5243\n",
      "\n",
      "\n",
      " refugees \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5073\n",
      "          1       0.04      0.99      0.07       170\n",
      "\n",
      "avg / total       0.97      0.17      0.25      5243\n",
      "\n",
      "\n",
      " death \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.26      4996\n",
      "          1       0.05      1.00      0.10       247\n",
      "\n",
      "avg / total       0.96      0.19      0.25      5243\n",
      "\n",
      "\n",
      " other_aid \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.16      0.27      4551\n",
      "          1       0.15      0.98      0.26       692\n",
      "\n",
      "avg / total       0.87      0.27      0.27      5243\n",
      "\n",
      "\n",
      " infrastructure_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.26      4907\n",
      "          1       0.07      0.99      0.14       336\n",
      "\n",
      "avg / total       0.93      0.20      0.25      5243\n",
      "\n",
      "\n",
      " transport \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.25      5008\n",
      "          1       0.05      0.98      0.10       235\n",
      "\n",
      "avg / total       0.95      0.18      0.25      5243\n",
      "\n",
      "\n",
      " buildings \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.26      4974\n",
      "          1       0.06      1.00      0.11       269\n",
      "\n",
      "avg / total       0.95      0.19      0.25      5243\n",
      "\n",
      "\n",
      " electricity \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5128\n",
      "          1       0.03      0.98      0.05       115\n",
      "\n",
      "avg / total       0.98      0.16      0.24      5243\n",
      "\n",
      "\n",
      " tools \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5208\n",
      "          1       0.01      1.00      0.02        35\n",
      "\n",
      "avg / total       0.99      0.15      0.24      5243\n",
      "\n",
      "\n",
      " hospitals \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5191\n",
      "          1       0.01      1.00      0.02        52\n",
      "\n",
      "avg / total       0.99      0.15      0.24      5243\n",
      "\n",
      "\n",
      " shops \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5218\n",
      "          1       0.01      0.96      0.01        25\n",
      "\n",
      "avg / total       0.99      0.14      0.24      5243\n",
      "\n",
      "\n",
      " aid_centers \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5179\n",
      "          1       0.01      0.95      0.03        64\n",
      "\n",
      "avg / total       0.98      0.15      0.24      5243\n",
      "\n",
      "\n",
      " other_infrastructure \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.25      5018\n",
      "          1       0.05      0.99      0.09       225\n",
      "\n",
      "avg / total       0.96      0.18      0.25      5243\n",
      "\n",
      "\n",
      " weather_related \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.19      0.32      3771\n",
      "          1       0.32      0.99      0.49      1472\n",
      "\n",
      "avg / total       0.79      0.41      0.36      5243\n",
      "\n",
      "\n",
      " floods \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.26      4812\n",
      "          1       0.09      0.99      0.17       431\n",
      "\n",
      "avg / total       0.92      0.22      0.26      5243\n",
      "\n",
      "\n",
      " storm \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.26      4764\n",
      "          1       0.10      0.99      0.19       479\n",
      "\n",
      "avg / total       0.91      0.23      0.26      5243\n",
      "\n",
      "\n",
      " fire \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.14      0.25      5190\n",
      "          1       0.01      0.92      0.02        53\n",
      "\n",
      "avg / total       0.98      0.15      0.24      5243\n",
      "\n",
      "\n",
      " earthquake \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.15      0.27      4728\n",
      "          1       0.11      1.00      0.20       515\n",
      "\n",
      "avg / total       0.91      0.24      0.26      5243\n",
      "\n",
      "\n",
      " cold \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25      5139\n",
      "          1       0.02      0.99      0.04       104\n",
      "\n",
      "avg / total       0.98      0.16      0.24      5243\n",
      "\n",
      "\n",
      " other_weather \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.15      0.25      4976\n",
      "          1       0.06      0.98      0.11       267\n",
      "\n",
      "avg / total       0.94      0.19      0.25      5243\n",
      "\n",
      "\n",
      " direct_report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.17      0.28      4233\n",
      "          1       0.22      0.98      0.36      1010\n",
      "\n",
      "avg / total       0.82      0.32      0.30      5243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "    (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"clf\", MultiOutputClassifier(RandomForestClassifier(n_jobs=-1)))\n",
    "])\n",
    "\n",
    "parameters = {\"clf__estimator__n_estimators\": [10,50,100]}\n",
    "\n",
    "cv = GridSearchCV(pipeline_rf, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying other transformers\n",
    "# through experimentation only NounCount improved performance\n",
    "\n",
    "class NounCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_nouns(self, text):\n",
    "        list_of_noun_tags = [\"NN\", \"NNP\", \"NNPS\", \"NNS\"]\n",
    "        noun_count = 0\n",
    "        for word, tag in pos_tag(tokenize(text)):\n",
    "            if tag in list_of_noun_tags:\n",
    "                noun_count += 1\n",
    "        return noun_count\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        text_transformed = pd.Series(X).apply(self.count_nouns)\n",
    "        return pd.DataFrame(text_transformed)\n",
    "    \n",
    "class MessageLength(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_nouns(self, text):\n",
    "        return len(text)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        text_transformed = pd.Series(X).apply(self.count_nouns)\n",
    "        return pd.DataFrame(text_transformed)\n",
    "    \n",
    "class NumberCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_nouns(self, text):\n",
    "        return len(re.sub(\"\\D\", \"\",text))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        text_transformed = pd.Series(X).apply(self.count_nouns)\n",
    "        return pd.DataFrame(text_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline():\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "            \n",
    "            ('count_noun', NounCount())\n",
    "        ])),\n",
    "\n",
    "        ('scale', StandardScaler(with_mean=False)),\n",
    "        ('clf', RandomForestClassifier(n_estimators=10, n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-823fe25739cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             delayed(_fit_transform_one)(trans, weight, X, y,\n\u001b[1;32m    738\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 739\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-715265c345b7>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtext_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-715265c345b7>\u001b[0m in \u001b[0;36mcount_nouns\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlist_of_noun_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"NN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NNP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NNPS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NNS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnoun_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_noun_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mnoun_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline().fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "\n",
      " Not enough inputs (total of 3 missing) were given to the programme. \n",
      " Please input the arguments in the following order:\n",
      " database directory, name of SQL table, save name for the machine learning model.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "class NounCount(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Input: Inherits from the sklean.base class\n",
    "    Creates: A transformer object that can be used to count the number of nouns in a corpus of documents\n",
    "    \"\"\"\n",
    "    \n",
    "    def count_nouns(self, text):\n",
    "        list_of_noun_tags = [\"NN\", \"NNP\", \"NNPS\", \"NNS\"]\n",
    "        noun_count = 0\n",
    "        for word, tag in pos_tag(tokenize(text)):\n",
    "            if tag in list_of_noun_tags:\n",
    "                noun_count += 1\n",
    "        return noun_count\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        text_transformed = pd.Series(X).apply(self.count_nouns)\n",
    "        return pd.DataFrame(text_transformed)\n",
    "\n",
    "def load_data(db, table):\n",
    "    \"\"\"\n",
    "    Inputs: The database and table name.\n",
    "    Outputs: The data split into train and test data for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = create_engine(db)\n",
    "    df = pd.read_sql_table(table, engine)  \n",
    "    X = df.message\n",
    "    Y = df.drop(labels=[\"id\",\"message\",\"original\",\"genre\"],axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Inputs: A singel document of unedited text.\n",
    "    Outputs: A single document of tokenized and standardized text.\n",
    "    \"\"\"\n",
    "    # remove punctuation and tokenize\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    token = tokenizer.tokenize(text.lower())\n",
    "\n",
    "    # remove stop words:\n",
    "    stopwords_english = stopwords.words(\"english\")\n",
    "    tokens = [word for word in token if word not in stopwords_english]\n",
    "    \n",
    "    return tokens\n",
    "        \n",
    "def model_pipeline():\n",
    "    \"\"\"\n",
    "    Inputs: None.\n",
    "    Outputs: Creates a data pipeline that transforms the data into a TF-IDF Vectorized form,\n",
    "             while in parallel creates a new feature that counts the nouns. The pipeline \n",
    "             then merges these together and scales the data before using it with a\n",
    "             RandomForeset Classifier. \n",
    "    \"\"\"\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "            \n",
    "            ('count_noun', NounCount())\n",
    "        ])),\n",
    "\n",
    "        ('scale', StandardScaler(with_mean=False)),\n",
    "        ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    parameters = {\"clf__n_estimators\":[10,50,100]}\n",
    "    model = GridSearchCV(pipeline, param_grid=parameters, verbose=1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def display_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Inputs: labelled data, the true value of Y data, and the predicted value of Y data.\n",
    "    Returns: the classification report for all the labels.\n",
    "    \"\"\"\n",
    "    for index, column in enumerate(y_true):\n",
    "        print(column, classification_report(y_true[column], y_pred[:, index]))\n",
    "        \n",
    "def save_model(model, filename):\n",
    "    pickle.dump(model, open(filename, \"wb\"))\n",
    "        \n",
    "def main(*args):\n",
    "    \"\"\"\n",
    "    Inputs: The database and sql table name.\n",
    "    Outputs: \n",
    "    \"\"\"\n",
    "    if len(args) == 3:\n",
    "        X_train, X_test, y_train, y_test = load_data(args[0], args[1])\n",
    "        print(\"\\n Data loaded successfully \\n\")\n",
    "        model = model_pipeline()\n",
    "        print(\"\\n Pipeline created successfully \\n\")\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"\\n Model trained successfully \\n\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"\\n Model Prediction completed \\n\")\n",
    "        display_results(y_test, y_pred)\n",
    "        print(\"\\n Displayed results successfully \\n\")\n",
    "        save_model(model, args[2])\n",
    "        print(\"\\n Saved model successfully \\n\")\n",
    "    else:\n",
    "        print(f\"\\n Not enough inputs (total of {3-len(args)} missing) were given to the programme. \\n\",\n",
    "             \"Please input the arguments in the following order:\\n\",\n",
    "             \"database directory, name of SQL table, save name for the machine learning model.\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data loaded successfully \n",
      "\n",
      "\n",
      " Pipeline created successfully \n",
      "\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 20.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model trained successfully \n",
      "\n",
      "\n",
      " Model Prediction completed \n",
      "\n",
      "related              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.53      0.59      1245\n",
      "          1       0.86      0.92      0.89      3998\n",
      "\n",
      "avg / total       0.82      0.83      0.82      5243\n",
      "\n",
      "request              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94      4352\n",
      "          1       0.84      0.48      0.61       891\n",
      "\n",
      "avg / total       0.89      0.90      0.88      5243\n",
      "\n",
      "offer              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5219\n",
      "          1       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5243\n",
      "\n",
      "aid_related              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.92      0.82      3079\n",
      "          1       0.82      0.54      0.65      2164\n",
      "\n",
      "avg / total       0.77      0.76      0.75      5243\n",
      "\n",
      "medical_help              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      4808\n",
      "          1       0.44      0.01      0.02       435\n",
      "\n",
      "avg / total       0.88      0.92      0.88      5243\n",
      "\n",
      "medical_products              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4964\n",
      "          1       0.80      0.03      0.06       279\n",
      "\n",
      "avg / total       0.94      0.95      0.92      5243\n",
      "\n",
      "search_and_rescue              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5107\n",
      "          1       0.62      0.04      0.07       136\n",
      "\n",
      "avg / total       0.97      0.97      0.96      5243\n",
      "\n",
      "security              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5147\n",
      "          1       0.50      0.01      0.02        96\n",
      "\n",
      "avg / total       0.97      0.98      0.97      5243\n",
      "\n",
      "military              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5085\n",
      "          1       0.75      0.06      0.11       158\n",
      "\n",
      "avg / total       0.96      0.97      0.96      5243\n",
      "\n",
      "child_alone              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5243\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5243\n",
      "\n",
      "water              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4908\n",
      "          1       0.89      0.26      0.41       335\n",
      "\n",
      "avg / total       0.95      0.95      0.94      5243\n",
      "\n",
      "food              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      4659\n",
      "          1       0.88      0.44      0.58       584\n",
      "\n",
      "avg / total       0.93      0.93      0.92      5243\n",
      "\n",
      "shelter              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      4775\n",
      "          1       0.84      0.18      0.30       468\n",
      "\n",
      "avg / total       0.92      0.92      0.90      5243\n",
      "\n",
      "clothing              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5173\n",
      "          1       0.73      0.11      0.20        70\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5243\n",
      "\n",
      "money              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5131\n",
      "          1       0.86      0.05      0.10       112\n",
      "\n",
      "avg / total       0.98      0.98      0.97      5243\n",
      "\n",
      "missing_people              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5180\n",
      "          1       0.00      0.00      0.00        63\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5243\n",
      "\n",
      "refugees              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5073\n",
      "          1       0.33      0.01      0.01       170\n",
      "\n",
      "avg / total       0.95      0.97      0.95      5243\n",
      "\n",
      "death              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      4996\n",
      "          1       1.00      0.04      0.08       247\n",
      "\n",
      "avg / total       0.96      0.95      0.93      5243\n",
      "\n",
      "other_aid              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93      4551\n",
      "          1       0.62      0.04      0.07       692\n",
      "\n",
      "avg / total       0.84      0.87      0.82      5243\n",
      "\n",
      "infrastructure_related              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      4907\n",
      "          1       0.00      0.00      0.00       336\n",
      "\n",
      "avg / total       0.88      0.94      0.90      5243\n",
      "\n",
      "transport              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5008\n",
      "          1       0.67      0.01      0.02       235\n",
      "\n",
      "avg / total       0.94      0.96      0.93      5243\n",
      "\n",
      "buildings              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4974\n",
      "          1       0.50      0.01      0.03       269\n",
      "\n",
      "avg / total       0.93      0.95      0.93      5243\n",
      "\n",
      "electricity              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5128\n",
      "          1       0.00      0.00      0.00       115\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5243\n",
      "\n",
      "tools              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5208\n",
      "          1       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5243\n",
      "\n",
      "hospitals              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5191\n",
      "          1       0.00      0.00      0.00        52\n",
      "\n",
      "avg / total       0.98      0.99      0.99      5243\n",
      "\n",
      "shops              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5218\n",
      "          1       0.00      0.00      0.00        25\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5243\n",
      "\n",
      "aid_centers              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5179\n",
      "          1       0.00      0.00      0.00        64\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5243\n",
      "\n",
      "other_infrastructure              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5018\n",
      "          1       0.00      0.00      0.00       225\n",
      "\n",
      "avg / total       0.92      0.96      0.94      5243\n",
      "\n",
      "weather_related              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91      3771\n",
      "          1       0.88      0.56      0.69      1472\n",
      "\n",
      "avg / total       0.86      0.86      0.84      5243\n",
      "\n",
      "floods              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      4812\n",
      "          1       0.92      0.25      0.40       431\n",
      "\n",
      "avg / total       0.94      0.94      0.92      5243\n",
      "\n",
      "storm              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      4764\n",
      "          1       0.78      0.29      0.43       479\n",
      "\n",
      "avg / total       0.92      0.93      0.91      5243\n",
      "\n",
      "fire              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5190\n",
      "          1       1.00      0.02      0.04        53\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5243\n",
      "\n",
      "earthquake              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97      4728\n",
      "          1       0.88      0.61      0.72       515\n",
      "\n",
      "avg / total       0.95      0.95      0.95      5243\n",
      "\n",
      "cold              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5139\n",
      "          1       0.50      0.01      0.02       104\n",
      "\n",
      "avg / total       0.97      0.98      0.97      5243\n",
      "\n",
      "other_weather              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4976\n",
      "          1       0.57      0.01      0.03       267\n",
      "\n",
      "avg / total       0.93      0.95      0.93      5243\n",
      "\n",
      "direct_report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92      4233\n",
      "          1       0.79      0.35      0.49      1010\n",
      "\n",
      "avg / total       0.85      0.86      0.83      5243\n",
      "\n",
      "\n",
      " Displayed results successfully \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved model successfully \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(\"sqlite:///InsertDatabaseName.db\", \"DisasterResponse\", \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
